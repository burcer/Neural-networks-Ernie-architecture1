{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/burc/anaconda2/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "0.0\n",
      "255.0\n",
      "(50000, 28, 28)\n",
      "14.1666666667\n",
      "240.833333333\n",
      "X_val:  (10000, 28, 28)\n",
      "X_train:  (50000, 28, 28)\n",
      "X_test:  (10000, 28, 28)\n",
      "y_val:  (10000,)\n",
      "y_train:  (50000,)\n",
      "y_test:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nn.classifiers.fc_net_split3 import *\n",
    "from nn.data_utils import get_CIFAR10_data\n",
    "from nn.data_utils_mnist import *\n",
    "from nn.gradient_check import eval_numerical_gradient, eval_numerical_gradient_array\n",
    "from nn.solver import Solver\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "data = get_MNIST_data(test_trinary=1,train_trinary=1,val_trinary=1,noise_amplitude=0.0,no_of_levels=9)\n",
    "for k, v in data.iteritems():\n",
    "  print '%s: ' % k, v.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=data['X_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cs231n/layers.py:237: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr=0.000127, std=0.082118, regu=0.003068, dec=0.902951 train accuracy is : 0.866000 val acc:  0.859900\n",
      " no decay lr=0.000127, std=0.082118,regu=0.003068 train accuracy is : 0.935000 val acc:  0.923900\n",
      "lr=0.000148, std=0.009687, regu=0.000580, dec=0.965749 train accuracy is : 0.893000 val acc:  0.899200\n",
      " no decay lr=0.000148, std=0.009687,regu=0.000580 train accuracy is : 0.978000 val acc:  0.963400\n",
      "lr=0.000314, std=0.023949, regu=0.035017, dec=0.983169 train accuracy is : 0.955000 val acc:  0.952100\n",
      " no decay lr=0.000314, std=0.023949,regu=0.035017 train accuracy is : 0.974000 val acc:  0.956800\n",
      "lr=0.001128, std=0.011237, regu=0.000103, dec=0.959561 train accuracy is : 0.993000 val acc:  0.974500\n",
      " no decay lr=0.001128, std=0.011237,regu=0.000103 train accuracy is : 0.985000 val acc:  0.978000\n",
      "lr=0.001850, std=0.073385, regu=0.019861, dec=0.985820 train accuracy is : 0.975000 val acc:  0.962000\n",
      " no decay lr=0.001850, std=0.073385,regu=0.019861 train accuracy is : 0.960000 val acc:  0.958500\n",
      "lr=0.001561, std=0.075842, regu=0.000462, dec=0.960285 train accuracy is : 0.977000 val acc:  0.960100\n",
      " no decay lr=0.001561, std=0.075842,regu=0.000462 train accuracy is : 0.975000 val acc:  0.973000\n",
      "lr=0.008137, std=0.007187, regu=0.003278, dec=0.947356 train accuracy is : 0.980000 val acc:  0.969900\n",
      " no decay lr=0.008137, std=0.007187,regu=0.003278 train accuracy is : 0.965000 val acc:  0.959700\n",
      "lr=0.007375, std=0.004525, regu=0.008185, dec=0.991002 train accuracy is : 0.972000 val acc:  0.969300\n",
      " no decay lr=0.007375, std=0.004525,regu=0.008185 train accuracy is : 0.965000 val acc:  0.962300\n",
      "lr=0.007450, std=0.007168, regu=0.000162, dec=0.966402 train accuracy is : 0.954000 val acc:  0.959200\n",
      " no decay lr=0.007450, std=0.007168,regu=0.000162 train accuracy is : 0.954000 val acc:  0.939500\n",
      "lr=0.007338, std=0.021954, regu=0.014342, dec=0.907942 train accuracy is : 0.977000 val acc:  0.968900\n",
      " no decay lr=0.007338, std=0.021954,regu=0.014342 train accuracy is : 0.971000 val acc:  0.967400\n",
      "lr=0.008127, std=0.014980, regu=0.000233, dec=0.983327 train accuracy is : 0.958000 val acc:  0.958900\n",
      " no decay lr=0.008127, std=0.014980,regu=0.000233 train accuracy is : 0.957000 val acc:  0.951300\n",
      "lr=0.001696, std=0.009110, regu=0.000467, dec=0.962276 train accuracy is : 0.992000 val acc:  0.976900\n",
      " no decay lr=0.001696, std=0.009110,regu=0.000467 train accuracy is : 0.975000 val acc:  0.971000\n",
      "lr=0.000140, std=0.037205, regu=0.003423, dec=0.939999 train accuracy is : 0.907000 val acc:  0.911400\n",
      " no decay lr=0.000140, std=0.037205,regu=0.003423 train accuracy is : 0.962000 val acc:  0.944300\n",
      "lr=0.000155, std=0.085353, regu=0.009060, dec=0.985264 train accuracy is : 0.925000 val acc:  0.914900\n",
      " no decay lr=0.000155, std=0.085353,regu=0.009060 train accuracy is : 0.947000 val acc:  0.927700\n",
      "lr=0.001016, std=0.075831, regu=0.000125, dec=0.918466 train accuracy is : 0.964000 val acc:  0.941400\n",
      " no decay lr=0.001016, std=0.075831,regu=0.000125 train accuracy is : 0.984000 val acc:  0.967700\n",
      "lr=0.005744, std=0.017081, regu=0.000116, dec=0.980187 train accuracy is : 0.973000 val acc:  0.964100\n",
      " no decay lr=0.005744, std=0.017081,regu=0.000116 train accuracy is : 0.956000 val acc:  0.949300\n",
      "lr=0.000305, std=0.043812, regu=0.000220, dec=0.981856 train accuracy is : 0.971000 val acc:  0.948900\n",
      " no decay lr=0.000305, std=0.043812,regu=0.000220 train accuracy is : 0.971000 val acc:  0.955100\n",
      "lr=0.002168, std=0.054506, regu=0.076899, dec=0.971738 train accuracy is : 0.930000 val acc:  0.936000\n",
      " no decay lr=0.002168, std=0.054506,regu=0.076899 train accuracy is : 0.928000 val acc:  0.925400\n",
      "lr=0.006577, std=0.038594, regu=0.000115, dec=0.968751 train accuracy is : 0.974000 val acc:  0.968300\n",
      " no decay lr=0.006577, std=0.038594,regu=0.000115 train accuracy is : 0.959000 val acc:  0.957900\n",
      "lr=0.006901, std=0.009387, regu=0.000239, dec=0.917836 train accuracy is : 0.972000 val acc:  0.965400\n",
      " no decay lr=0.006901, std=0.009387,regu=0.000239 train accuracy is : 0.944000 val acc:  0.952800\n",
      "lr=0.000950, std=0.045820, regu=0.000707, dec=0.967808 train accuracy is : 0.982000 val acc:  0.961700\n",
      " no decay lr=0.000950, std=0.045820,regu=0.000707 train accuracy is : 0.991000 val acc:  0.971800\n",
      "lr=0.001867, std=0.005349, regu=0.026774, dec=0.954150 train accuracy is : 0.974000 val acc:  0.965200\n",
      " no decay lr=0.001867, std=0.005349,regu=0.026774 train accuracy is : 0.972000 val acc:  0.965400\n",
      "lr=0.003726, std=0.072185, regu=0.000412, dec=0.974395 train accuracy is : 0.986000 val acc:  0.976000\n",
      " no decay lr=0.003726, std=0.072185,regu=0.000412 train accuracy is : 0.974000 val acc:  0.970100\n",
      "lr=0.001425, std=0.004176, regu=0.041502, dec=0.948886 train accuracy is : 0.973000 val acc:  0.961500\n",
      " no decay lr=0.001425, std=0.004176,regu=0.041502 train accuracy is : 0.968000 val acc:  0.958500\n",
      "lr=0.000127, std=0.046184, regu=0.000111, dec=0.915795 train accuracy is : 0.893000 val acc:  0.896500\n",
      " no decay lr=0.000127, std=0.046184,regu=0.000111 train accuracy is : 0.959000 val acc:  0.937000\n",
      "lr=0.000690, std=0.030015, regu=0.027783, dec=0.953170 train accuracy is : 0.957000 val acc:  0.954600\n",
      " no decay lr=0.000690, std=0.030015,regu=0.027783 train accuracy is : 0.960000 val acc:  0.960500\n",
      "lr=0.006973, std=0.003693, regu=0.006326, dec=0.919996 train accuracy is : 0.972000 val acc:  0.970600\n",
      " no decay lr=0.006973, std=0.003693,regu=0.006326 train accuracy is : 0.968000 val acc:  0.965400\n",
      "lr=0.005487, std=0.047895, regu=0.084077, dec=0.910375 train accuracy is : 0.951000 val acc:  0.937000\n",
      " no decay lr=0.005487, std=0.047895,regu=0.084077 train accuracy is : 0.923000 val acc:  0.912700\n",
      "lr=0.000842, std=0.045882, regu=0.000123, dec=0.963136 train accuracy is : 0.979000 val acc:  0.959500\n",
      " no decay lr=0.000842, std=0.045882,regu=0.000123 train accuracy is : 0.994000 val acc:  0.972300\n",
      "lr=0.001328, std=0.007702, regu=0.001093, dec=0.974352 train accuracy is : 0.996000 val acc:  0.978400\n",
      " no decay lr=0.001328, std=0.007702,regu=0.001093 train accuracy is : 0.984000 val acc:  0.977600\n",
      "lr=0.000340, std=0.058508, regu=0.026176, dec=0.905490 train accuracy is : 0.919000 val acc:  0.920700\n",
      " no decay lr=0.000340, std=0.058508,regu=0.026176 train accuracy is : 0.956000 val acc:  0.950500\n",
      "lr=0.000251, std=0.004352, regu=0.004625, dec=0.988481 train accuracy is : 0.895000 val acc:  0.876000\n",
      " no decay lr=0.000251, std=0.004352,regu=0.004625 train accuracy is : 0.909000 val acc:  0.880700\n",
      "lr=0.000164, std=0.003599, regu=0.070504, dec=0.984579 train accuracy is : 0.870000 val acc:  0.867800\n",
      " no decay lr=0.000164, std=0.003599,regu=0.070504 train accuracy is : 0.879000 val acc:  0.890100\n",
      "lr=0.001270, std=0.009218, regu=0.000252, dec=0.927900 train accuracy is : 0.992000 val acc:  0.974500\n",
      " no decay lr=0.001270, std=0.009218,regu=0.000252 train accuracy is : 0.983000 val acc:  0.975600\n",
      "lr=0.004641, std=0.011786, regu=0.006556, dec=0.991849 train accuracy is : 0.986000 val acc:  0.973300\n",
      " no decay lr=0.004641, std=0.011786,regu=0.006556 train accuracy is : 0.973000 val acc:  0.972200\n",
      "lr=0.000973, std=0.006559, regu=0.000168, dec=0.910148 train accuracy is : 0.900000 val acc:  0.887200\n",
      " no decay lr=0.000973, std=0.006559,regu=0.000168 train accuracy is : 0.991000 val acc:  0.978300\n",
      "lr=0.002229, std=0.048597, regu=0.000129, dec=0.943010 train accuracy is : 0.986000 val acc:  0.967400\n",
      " no decay lr=0.002229, std=0.048597,regu=0.000129 train accuracy is : 0.980000 val acc:  0.974200\n",
      "lr=0.000706, std=0.004516, regu=0.022547, dec=0.967916 train accuracy is : 0.973000 val acc:  0.965500\n",
      " no decay lr=0.000706, std=0.004516,regu=0.022547 train accuracy is : 0.985000 val acc:  0.967000\n",
      "lr=0.002580, std=0.008112, regu=0.000513, dec=0.941975 train accuracy is : 0.991000 val acc:  0.977200\n",
      " no decay lr=0.002580, std=0.008112,regu=0.000513 train accuracy is : 0.973000 val acc:  0.966200\n",
      "lr=0.004169, std=0.003315, regu=0.059853, dec=0.982492 train accuracy is : 0.950000 val acc:  0.947900\n",
      " no decay lr=0.004169, std=0.003315,regu=0.059853 train accuracy is : 0.930000 val acc:  0.939200\n",
      "lr=0.000115, std=0.029228, regu=0.000166, dec=0.933385 train accuracy is : 0.930000 val acc:  0.907100\n",
      " no decay lr=0.000115, std=0.029228,regu=0.000166 train accuracy is : 0.958000 val acc:  0.944000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-04cfd60d53be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m          )\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0msolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m'lr=%f, std=%f, regu=%f, dec=%f train accuracy is : %f val acc:  %f'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_scale\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_acc_history\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mval_acc_history\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/burc/assignment2/cs231n/solver.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m       \u001b[1;31m# Maybe print training loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/burc/assignment2/cs231n/solver.pyc\u001b[0m in \u001b[0;36m_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;31m# Compute loss and gradient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/burc/assignment2/cs231n/classifiers/fc_net_split3.pyc\u001b[0m in \u001b[0;36mloss\u001b[1;34m(self, X, y, noise, noise2, test, parallel_samples_output)\u001b[0m\n\u001b[0;32m    188\u001b[0m         \u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#change to\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[1;33m==\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m         \u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpwlsig_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#change tos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[1;33m==\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[0mhidden2_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtmp1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtanh_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#change to\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/burc/assignment2/cs231n/layers.pyc\u001b[0m in \u001b[0;36mtanh_forward\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    154\u001b[0m   \u001b[1;31m#############################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m   \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m   \u001b[1;31m#############################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/burc/assignment2/cs231n/layers.pyc\u001b[0m in \u001b[0;36msigmoid\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#lr=0.001530, std=0.008238, regu=0.000000 train accuracy is : 0.990000 val acc:  0.975800\n",
    "#no decay lr=0.001002, std=0.021410,regu=0.000750 train accuracy is : 0.990000 val acc:  0.977400\n",
    "#no decay lr=0.000541, std=0.010023,regu=0.000685 train accuracy is : 0.992000 val acc:  0.977300\n",
    "for i in range(100):\n",
    "    #learning_rate = 0.000830 #10**np.random.uniform(-4,-3)\n",
    "    #weight_scale = 0.003849 #10**np.random.uniform(-3,-1)\n",
    "    #regu = 0.00168276907439#10**np.random.uniform(-3,-1)\n",
    "    regu=10**np.random.uniform(-4,-1)\n",
    "    #regu=0\n",
    "    learning_rate = 10**np.random.uniform(-4,-2)\n",
    "    weight_scale = 10**np.random.uniform(-2.5,-1)\n",
    "    dec = np.random.uniform(0.9,1)\n",
    "    #regu =0.00329329787291\n",
    "    #print regu\n",
    "    #learning_rate=0.0005\n",
    "    #weight_scale=0.027\n",
    "    #learning_rate = 0.001 #10**np.random.uniform(-5,-1)\n",
    "    #weight_scale = 0.02 #10**np.random.uniform(-3,0)\n",
    "    # no decay lr=0.000292, std=0.004709, train accuracy is : 0.999000 val acc:  0.970500\n",
    "#0.14912609128\n",
    "#0.00669438412009\n",
    "#0.00168276907439\n",
    "# no decay lr=0.000830, std=0.003849, train accuracy is : 0.994000 val acc:  0.967100\n",
    "# no decay lr=0.000508, std=0.027556, train accuracy is : 1.000000 val acc:  0.971500\n",
    "\n",
    "    model = ThreeLayerNet(input_dim=28*28, ##hidden_dim=256,\n",
    "              weight_scale=weight_scale, reg=regu, activation=3, scores_activation=3)\n",
    "    solver = Solver(model,data,\n",
    "                print_every=10, num_epochs=60, batch_size=100,\n",
    "                update_rule='sgd_momentum',lr_decay=dec,verbose = False,\n",
    "                optim_config={\n",
    "                  'learning_rate': learning_rate\n",
    "                }\n",
    "         )\n",
    "    \n",
    "    solver.train()\n",
    "\n",
    "    print 'lr=%f, std=%f, regu=%f, dec=%f train accuracy is : %f val acc:  %f' %(learning_rate, weight_scale, regu, dec,solver.train_acc_history[-1], solver.val_acc_history[-1])\n",
    " \n",
    "\n",
    "    model = ThreeLayerNet(input_dim=28*28,  ##hidden_dim=256,\n",
    "              weight_scale=weight_scale, reg=regu,activation=3, scores_activation=3)\n",
    "    solver = Solver(model,data,\n",
    "                print_every=4000, num_epochs=60, batch_size=100, \n",
    "                update_rule='sgd_momentum',lr_decay=1.0,verbose =False, #lr_decay=0.0,\n",
    "                optim_config={\n",
    "                  'learning_rate': learning_rate\n",
    "                }\n",
    "         )\n",
    "    solver.train()\n",
    "    print ' no decay lr=%f, std=%f,regu=%f train accuracy is : %f val acc:  %f' %(learning_rate, weight_scale,regu, solver.train_acc_history[-1], solver.val_acc_history[-1])\n",
    " \n",
    "\n",
    "\n",
    "#solver.train()\n",
    "\n",
    "plt.plot(solver.loss_history, 'o')\n",
    "plt.title('Training loss history')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Training loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lr=0.001328, std=0.007702, regu=0.001093, dec=0.974352 train accuracy is : 0.996000 val acc:  0.978400\n",
    "\n",
    "regu=0.001093\n",
    "    #regu=0\n",
    "learning_rate = 0.001328\n",
    "weight_scale = 0.007702\n",
    "dec = 0.974352\n",
    "    #regu =0.00329329787291\n",
    "    #print regu\n",
    "    #learning_rate=0.0005\n",
    "    #weight_scale=0.027\n",
    "    #learning_rate = 0.001 #10**np.random.uniform(-5,-1)\n",
    "    #weight_scale = 0.02 #10**np.random.uniform(-3,0)\n",
    "    # no decay lr=0.000292, std=0.004709, train accuracy is : 0.999000 val acc:  0.970500\n",
    "#0.14912609128\n",
    "#0.00669438412009\n",
    "#0.00168276907439\n",
    "# no decay lr=0.000830, std=0.003849, train accuracy is : 0.994000 val acc:  0.967100\n",
    "# no decay lr=0.000508, std=0.027556, train accuracy is : 1.000000 val acc:  0.971500\n",
    "\n",
    "model = ThreeLayerNet(input_dim=28*28, ##hidden_dim=256,\n",
    "              weight_scale=weight_scale, reg=regu, activation=3, scores_activation=3)\n",
    "solver = Solver(model,data,\n",
    "                print_every=10, num_epochs=60, batch_size=100,\n",
    "                update_rule='sgd_momentum',lr_decay=dec,verbose = False,\n",
    "                optim_config={\n",
    "                  'learning_rate': learning_rate\n",
    "                }\n",
    "         )\n",
    "    \n",
    "solver.train()\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr=0.001328, std=0.007702,regu=0.001093 train accuracy is : 0.991000 val acc:  0.979200\n"
     ]
    }
   ],
   "source": [
    "  print 'lr=%f, std=%f,regu=%f train accuracy is : %f val acc:  %f' %(learning_rate, weight_scale,regu, solver.train_acc_history[-1], solver.val_acc_history[-1])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set accuracy:  0.9792\n",
      "Test set accuracy:  0.978\n",
      "Noisy test set accuracy:  0.9777\n",
      "0.976475\n",
      "0.9768\n",
      "0.97702\n",
      "0.977105\n",
      "0.977155\n",
      "0.977195\n",
      "0.97712\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_test_pred = np.argmax(model.loss(data['X_test'],noise=0,test=1), axis=1)\n",
    "y_val_pred = np.argmax(model.loss(data['X_val']), axis=1)\n",
    "print 'Validation set accuracy: ', (y_val_pred == data['y_val']).mean()\n",
    "print 'Test set accuracy: ', (y_test_pred == data['y_test']).mean()\n",
    "y_test_pred = np.argmax(model.loss(data['X_test'],noise=1,test=1), axis=1)\n",
    "print 'Noisy test set accuracy: ', (y_test_pred == data['y_test']).mean()\n",
    "\n",
    "par=1\n",
    "aa=0.0\n",
    "for i in range(0,20):\n",
    "  y_test_pred = np.argmax(model.loss(data['X_test'],noise=1,test=1,noise2=1, parallel_samples_output=par), axis=1)\n",
    "  #print 'Noisy test set accuracy: ', (y_test_pred == data['y_test']).mean()\n",
    "  aa=aa+ (y_test_pred == data['y_test']).mean()\n",
    "print aa/20\n",
    "\n",
    "par=2\n",
    "aa=0.0\n",
    "for i in range(0,20):\n",
    "  y_test_pred = np.argmax(model.loss(data['X_test'],noise=1,test=1,noise2=1, parallel_samples_output=par), axis=1)\n",
    "  #print 'Noisy test set accuracy: ', (y_test_pred == data['y_test']).mean()\n",
    "  aa=aa+ (y_test_pred == data['y_test']).mean()\n",
    "print aa/20\n",
    "\n",
    "\n",
    "par=3\n",
    "aa=0.0\n",
    "for i in range(0,20):\n",
    "  y_test_pred = np.argmax(model.loss(data['X_test'],noise=1,test=1,noise2=1, parallel_samples_output=par), axis=1)\n",
    "  #print 'Noisy test set accuracy: ', (y_test_pred == data['y_test']).mean()\n",
    "  aa=aa+ (y_test_pred == data['y_test']).mean()\n",
    "print aa/20\n",
    "\n",
    "par=4\n",
    "aa=0.0\n",
    "for i in range(0,20):\n",
    "  y_test_pred = np.argmax(model.loss(data['X_test'],noise=1,test=1,noise2=1, parallel_samples_output=par), axis=1)\n",
    "  #print 'Noisy test set accuracy: ', (y_test_pred == data['y_test']).mean()\n",
    "  aa=aa+ (y_test_pred == data['y_test']).mean()\n",
    "print aa/20\n",
    "\n",
    "par=8\n",
    "aa=0.0\n",
    "for i in range(0,20):\n",
    "  y_test_pred = np.argmax(model.loss(data['X_test'],noise=1,test=1,noise2=1, parallel_samples_output=par), axis=1)\n",
    "  #print 'Noisy test set accuracy: ', (y_test_pred == data['y_test']).mean()\n",
    "  aa=aa+ (y_test_pred == data['y_test']).mean()\n",
    "print aa/20\n",
    "\n",
    "par=16\n",
    "aa=0.0\n",
    "for i in range(0,20):\n",
    "  y_test_pred = np.argmax(model.loss(data['X_test'],noise=1,test=1,noise2=1, parallel_samples_output=par), axis=1)\n",
    "  #print 'Noisy test set accuracy: ', (y_test_pred == data['y_test']).mean()\n",
    "  aa=aa+ (y_test_pred == data['y_test']).mean()\n",
    "print aa/20\n",
    "\n",
    "par=24\n",
    "aa=0.0\n",
    "for i in range(0,20):\n",
    "  y_test_pred = np.argmax(model.loss(data['X_test'],noise=1,test=1,noise2=1, parallel_samples_output=par), axis=1)\n",
    "  #print 'Noisy test set accuracy: ', (y_test_pred == data['y_test']).mean()\n",
    "  aa=aa+ (y_test_pred == data['y_test']).mean()\n",
    "print aa/20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7840,)\n",
      "0 1231\n",
      "(10, 28, 28)\n",
      "0 1 784 28\n",
      "(10, 784)\n"
     ]
    }
   ],
   "source": [
    "y= np.array(range(0,28*28*10))\n",
    "print y.shape\n",
    "\n",
    "print y[0], y[1231]\n",
    "y2= np.reshape(y,(10,28,28))\n",
    "print y2.shape\n",
    "print y2[0,0,0], y2[0,0,1], y2[1,0,0], y2[0,1,0]\n",
    "\n",
    "y3 = np.reshape(y2, (y2.shape[0],-1))\n",
    "print y3.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " no decay lr=0.001002, std=0.021410,regu=0.000750 train accuracy is : 0.988000 val acc:  0.977800\n"
     ]
    }
   ],
   "source": [
    "###no decay lr=0.001002, std=0.021410,regu=0.000750 train accuracy is : 0.990000 val acc:  0.977400\n",
    "\n",
    "regu=0.000750\n",
    "    #regu=0\n",
    "learning_rate = 0.001002\n",
    "weight_scale = 0.021410\n",
    "\n",
    "model = ThreeLayerNet(input_dim=28*28,  ##hidden_dim=256,\n",
    "              weight_scale=weight_scale, reg=regu,activation=3, scores_activation=3)\n",
    "solver = Solver(model,data,\n",
    "                print_every=4000, num_epochs=60, batch_size=100, \n",
    "                update_rule='sgd_momentum',lr_decay=1.0,verbose =False, #lr_decay=0.0,\n",
    "                optim_config={\n",
    "                  'learning_rate': learning_rate\n",
    "                }\n",
    "         )\n",
    "solver.train()\n",
    "print ' no decay lr=%f, std=%f,regu=%f train accuracy is : %f val acc:  %f' %(learning_rate, weight_scale,regu, solver.train_acc_history[-1], solver.val_acc_history[-1])\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set accuracy:  0.9787\n",
      "Test set accuracy:  0.9764\n",
      "Noisy test set accuracy:  0.9747\n",
      "0.96633\n",
      "0.96956\n",
      "0.971335\n",
      "0.97213\n",
      "0.972865\n",
      "0.97291\n",
      "0.972925\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = np.argmax(model.loss(data['X_test'],noise=0,test=1), axis=1)\n",
    "y_val_pred = np.argmax(model.loss(data['X_val']), axis=1)\n",
    "print 'Validation set accuracy: ', (y_val_pred == data['y_val']).mean()\n",
    "print 'Test set accuracy: ', (y_test_pred == data['y_test']).mean()\n",
    "y_test_pred = np.argmax(model.loss(data['X_test'],noise=1,test=1), axis=1)\n",
    "print 'Noisy test set accuracy: ', (y_test_pred == data['y_test']).mean()\n",
    "\n",
    "par=1\n",
    "aa=0.0\n",
    "for i in range(0,20):\n",
    "  y_test_pred = np.argmax(model.loss(data['X_test'],noise=1,test=1,noise2=1, parallel_samples_output=par), axis=1)\n",
    "  #print 'Noisy test set accuracy: ', (y_test_pred == data['y_test']).mean()\n",
    "  aa=aa+ (y_test_pred == data['y_test']).mean()\n",
    "print aa/20\n",
    "\n",
    "par=2\n",
    "aa=0.0\n",
    "for i in range(0,20):\n",
    "  y_test_pred = np.argmax(model.loss(data['X_test'],noise=1,test=1,noise2=1, parallel_samples_output=par), axis=1)\n",
    "  #print 'Noisy test set accuracy: ', (y_test_pred == data['y_test']).mean()\n",
    "  aa=aa+ (y_test_pred == data['y_test']).mean()\n",
    "print aa/20\n",
    "\n",
    "\n",
    "par=3\n",
    "aa=0.0\n",
    "for i in range(0,20):\n",
    "  y_test_pred = np.argmax(model.loss(data['X_test'],noise=1,test=1,noise2=1, parallel_samples_output=par), axis=1)\n",
    "  #print 'Noisy test set accuracy: ', (y_test_pred == data['y_test']).mean()\n",
    "  aa=aa+ (y_test_pred == data['y_test']).mean()\n",
    "print aa/20\n",
    "\n",
    "par=4\n",
    "aa=0.0\n",
    "for i in range(0,20):\n",
    "  y_test_pred = np.argmax(model.loss(data['X_test'],noise=1,test=1,noise2=1, parallel_samples_output=par), axis=1)\n",
    "  #print 'Noisy test set accuracy: ', (y_test_pred == data['y_test']).mean()\n",
    "  aa=aa+ (y_test_pred == data['y_test']).mean()\n",
    "print aa/20\n",
    "\n",
    "par=8\n",
    "aa=0.0\n",
    "for i in range(0,20):\n",
    "  y_test_pred = np.argmax(model.loss(data['X_test'],noise=1,test=1,noise2=1, parallel_samples_output=par), axis=1)\n",
    "  #print 'Noisy test set accuracy: ', (y_test_pred == data['y_test']).mean()\n",
    "  aa=aa+ (y_test_pred == data['y_test']).mean()\n",
    "print aa/20\n",
    "\n",
    "par=16\n",
    "aa=0.0\n",
    "for i in range(0,20):\n",
    "  y_test_pred = np.argmax(model.loss(data['X_test'],noise=1,test=1,noise2=1, parallel_samples_output=par), axis=1)\n",
    "  #print 'Noisy test set accuracy: ', (y_test_pred == data['y_test']).mean()\n",
    "  aa=aa+ (y_test_pred == data['y_test']).mean()\n",
    "print aa/20\n",
    "\n",
    "par=24\n",
    "aa=0.0\n",
    "for i in range(0,20):\n",
    "  y_test_pred = np.argmax(model.loss(data['X_test'],noise=1,test=1,noise2=1, parallel_samples_output=par), axis=1)\n",
    "  #print 'Noisy test set accuracy: ', (y_test_pred == data['y_test']).mean()\n",
    "  aa=aa+ (y_test_pred == data['y_test']).mean()\n",
    "print aa/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
