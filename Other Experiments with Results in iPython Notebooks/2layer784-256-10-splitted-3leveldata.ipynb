{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "(60000,)\n",
      "0.0\n",
      "255.0\n",
      "(50000, 28, 28)\n",
      "42.5\n",
      "212.5\n",
      "X_val:  (10000, 28, 28)\n",
      "X_train:  (50000, 28, 28)\n",
      "X_test:  (10000, 28, 28)\n",
      "y_val:  (10000,)\n",
      "y_train:  (50000,)\n",
      "y_test:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nn.classifiers.fc_net_split import *\n",
    "from nn.data_utils import get_CIFAR10_data\n",
    "from nn.data_utils_mnist import *\n",
    "from nn.gradient_check import eval_numerical_gradient, eval_numerical_gradient_array\n",
    "from nn.solver import Solver\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "data = get_MNIST_data(test_trinary=1,train_trinary=1,val_trinary=1,noise_amplitude=0.0,no_of_levels=3)\n",
    "for k, v in data.iteritems():\n",
    "  print '%s: ' % k, v.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=data['X_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr=0.000530, std=0.003710, regu=0.035453 train accuracy is : 0.974000 val acc:  0.964500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cs231n/layers.py:237: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " no decay lr=0.000530, std=0.003710,regu=0.035453 train accuracy is : 0.969000 val acc:  0.964200\n",
      "lr=0.000621, std=0.000178, regu=0.001569 train accuracy is : 0.979000 val acc:  0.967000\n",
      " no decay lr=0.000621, std=0.000178,regu=0.001569 train accuracy is : 0.969000 val acc:  0.970200\n",
      "lr=0.000197, std=0.000267, regu=0.000123 train accuracy is : 0.973000 val acc:  0.962100\n",
      " no decay lr=0.000197, std=0.000267,regu=0.000123 train accuracy is : 0.985000 val acc:  0.968900\n",
      "lr=0.000148, std=0.001540, regu=0.045803 train accuracy is : 0.970000 val acc:  0.957700\n",
      " no decay lr=0.000148, std=0.001540,regu=0.045803 train accuracy is : 0.967000 val acc:  0.960900\n",
      "lr=0.000185, std=0.003367, regu=0.008021 train accuracy is : 0.966000 val acc:  0.960600\n",
      " no decay lr=0.000185, std=0.003367,regu=0.008021 train accuracy is : 0.987000 val acc:  0.969600\n",
      "lr=0.000842, std=0.000447, regu=0.018602 train accuracy is : 0.975000 val acc:  0.965900\n",
      " no decay lr=0.000842, std=0.000447,regu=0.018602 train accuracy is : 0.972000 val acc:  0.963200\n",
      "lr=0.000745, std=0.000328, regu=0.003728 train accuracy is : 0.989000 val acc:  0.968900\n",
      " no decay lr=0.000745, std=0.000328,regu=0.003728 train accuracy is : 0.962000 val acc:  0.966200\n",
      "lr=0.000208, std=0.008643, regu=0.000208 train accuracy is : 0.958000 val acc:  0.957300\n",
      " no decay lr=0.000208, std=0.008643,regu=0.000208 train accuracy is : 0.980000 val acc:  0.968900\n",
      "lr=0.000676, std=0.000155, regu=0.044615 train accuracy is : 0.971000 val acc:  0.964400\n",
      " no decay lr=0.000676, std=0.000155,regu=0.044615 train accuracy is : 0.975000 val acc:  0.962200\n",
      "lr=0.000156, std=0.005440, regu=0.001135 train accuracy is : 0.964000 val acc:  0.957300\n",
      " no decay lr=0.000156, std=0.005440,regu=0.001135 train accuracy is : 0.981000 val acc:  0.967400\n",
      "lr=0.000745, std=0.000179, regu=0.000626 train accuracy is : 0.982000 val acc:  0.968500\n",
      " no decay lr=0.000745, std=0.000179,regu=0.000626 train accuracy is : 0.973000 val acc:  0.963300\n",
      "lr=0.000696, std=0.006150, regu=0.017584 train accuracy is : 0.978000 val acc:  0.964800\n",
      " no decay lr=0.000696, std=0.006150,regu=0.017584 train accuracy is : 0.975000 val acc:  0.969300\n",
      "lr=0.000135, std=0.000195, regu=0.000105 train accuracy is : 0.967000 val acc:  0.959500\n",
      " no decay lr=0.000135, std=0.000195,regu=0.000105 train accuracy is : 0.982000 val acc:  0.967700\n",
      "lr=0.000612, std=0.000842, regu=0.000541 train accuracy is : 0.983000 val acc:  0.967400\n",
      " no decay lr=0.000612, std=0.000842,regu=0.000541 train accuracy is : 0.978000 val acc:  0.968400\n",
      "lr=0.000148, std=0.000156, regu=0.037218 train accuracy is : 0.958000 val acc:  0.957400\n",
      " no decay lr=0.000148, std=0.000156,regu=0.037218 train accuracy is : 0.973000 val acc:  0.962400\n",
      "lr=0.000211, std=0.002977, regu=0.007540 train accuracy is : 0.965000 val acc:  0.962000\n",
      " no decay lr=0.000211, std=0.002977,regu=0.007540 train accuracy is : 0.986000 val acc:  0.968300\n",
      "lr=0.000342, std=0.008827, regu=0.000458 train accuracy is : 0.971000 val acc:  0.962300\n",
      " no decay lr=0.000342, std=0.008827,regu=0.000458 train accuracy is : 0.977000 val acc:  0.969700\n",
      "lr=0.000509, std=0.002704, regu=0.065930 train accuracy is : 0.973000 val acc:  0.958800\n",
      " no decay lr=0.000509, std=0.002704,regu=0.065930 train accuracy is : 0.967000 val acc:  0.960600\n",
      "lr=0.000437, std=0.002138, regu=0.077799 train accuracy is : 0.971000 val acc:  0.958400\n",
      " no decay lr=0.000437, std=0.002138,regu=0.077799 train accuracy is : 0.961000 val acc:  0.957400\n",
      "lr=0.000174, std=0.000429, regu=0.012546 train accuracy is : 0.967000 val acc:  0.961800\n",
      " no decay lr=0.000174, std=0.000429,regu=0.012546 train accuracy is : 0.982000 val acc:  0.968400\n",
      "lr=0.000356, std=0.000535, regu=0.004881 train accuracy is : 0.978000 val acc:  0.967800\n",
      " no decay lr=0.000356, std=0.000535,regu=0.004881 train accuracy is : 0.981000 val acc:  0.972500\n",
      "lr=0.000502, std=0.000941, regu=0.092997 train accuracy is : 0.969000 val acc:  0.958000\n",
      " no decay lr=0.000502, std=0.000941,regu=0.092997 train accuracy is : 0.965000 val acc:  0.957900\n",
      "lr=0.000222, std=0.008396, regu=0.000662 train accuracy is : 0.964000 val acc:  0.954900\n",
      " no decay lr=0.000222, std=0.008396,regu=0.000662 train accuracy is : 0.983000 val acc:  0.969100\n",
      "lr=0.000233, std=0.000171, regu=0.002822 train accuracy is : 0.972000 val acc:  0.964500\n",
      " no decay lr=0.000233, std=0.000171,regu=0.002822 train accuracy is : 0.987000 val acc:  0.970100\n",
      "lr=0.000861, std=0.000757, regu=0.000742 train accuracy is : 0.980000 val acc:  0.967900\n",
      " no decay lr=0.000861, std=0.000757,regu=0.000742 train accuracy is : 0.970000 val acc:  0.962100\n",
      "lr=0.000170, std=0.001776, regu=0.003106 train accuracy is : 0.970000 val acc:  0.960700\n",
      " no decay lr=0.000170, std=0.001776,regu=0.003106 train accuracy is : 0.985000 val acc:  0.969200\n",
      "lr=0.000108, std=0.000260, regu=0.000140 train accuracy is : 0.970000 val acc:  0.955800\n",
      " no decay lr=0.000108, std=0.000260,regu=0.000140 train accuracy is : 0.984000 val acc:  0.965600\n",
      "lr=0.000484, std=0.000273, regu=0.020586 train accuracy is : 0.980000 val acc:  0.965700\n",
      " no decay lr=0.000484, std=0.000273,regu=0.020586 train accuracy is : 0.982000 val acc:  0.967100\n",
      "lr=0.000288, std=0.000309, regu=0.000245 train accuracy is : 0.976000 val acc:  0.967000\n",
      " no decay lr=0.000288, std=0.000309,regu=0.000245 train accuracy is : 0.979000 val acc:  0.971200\n",
      "lr=0.000354, std=0.001213, regu=0.006034 train accuracy is : 0.977000 val acc:  0.965200\n",
      " no decay lr=0.000354, std=0.001213,regu=0.006034 train accuracy is : 0.988000 val acc:  0.971700\n",
      "lr=0.000860, std=0.000123, regu=0.081453 train accuracy is : 0.967000 val acc:  0.958700\n",
      " no decay lr=0.000860, std=0.000123,regu=0.081453 train accuracy is : 0.952000 val acc:  0.954700\n",
      "lr=0.000229, std=0.000102, regu=0.000309 train accuracy is : 0.973000 val acc:  0.961200\n",
      " no decay lr=0.000229, std=0.000102,regu=0.000309 train accuracy is : 0.988000 val acc:  0.969900\n",
      "lr=0.000261, std=0.000859, regu=0.003976 train accuracy is : 0.978000 val acc:  0.966200\n",
      " no decay lr=0.000261, std=0.000859,regu=0.003976 train accuracy is : 0.986000 val acc:  0.970200\n",
      "lr=0.000157, std=0.000341, regu=0.076596 train accuracy is : 0.965000 val acc:  0.956000\n",
      " no decay lr=0.000157, std=0.000341,regu=0.076596 train accuracy is : 0.960000 val acc:  0.960700\n",
      "lr=0.000286, std=0.002045, regu=0.000108 train accuracy is : 0.983000 val acc:  0.964200\n",
      " no decay lr=0.000286, std=0.002045,regu=0.000108 train accuracy is : 0.977000 val acc:  0.970700\n",
      "lr=0.000850, std=0.003555, regu=0.006450 train accuracy is : 0.982000 val acc:  0.968200\n",
      " no decay lr=0.000850, std=0.003555,regu=0.006450 train accuracy is : 0.982000 val acc:  0.966700\n",
      "lr=0.000207, std=0.000106, regu=0.000187 train accuracy is : 0.969000 val acc:  0.963800\n",
      " no decay lr=0.000207, std=0.000106,regu=0.000187 train accuracy is : 0.988000 val acc:  0.970900\n",
      "lr=0.000426, std=0.001470, regu=0.001842 train accuracy is : 0.989000 val acc:  0.967000\n",
      " no decay lr=0.000426, std=0.001470,regu=0.001842 train accuracy is : 0.991000 val acc:  0.971300\n",
      "lr=0.000246, std=0.000568, regu=0.001668 train accuracy is : 0.978000 val acc:  0.964600\n",
      " no decay lr=0.000246, std=0.000568,regu=0.001668 train accuracy is : 0.984000 val acc:  0.969200\n",
      "lr=0.000348, std=0.000145, regu=0.001063 train accuracy is : 0.987000 val acc:  0.966900\n",
      " no decay lr=0.000348, std=0.000145,regu=0.001063 train accuracy is : 0.985000 val acc:  0.971400\n",
      "lr=0.000158, std=0.000128, regu=0.000555 train accuracy is : 0.962000 val acc:  0.961200\n",
      " no decay lr=0.000158, std=0.000128,regu=0.000555 train accuracy is : 0.978000 val acc:  0.967900\n",
      "lr=0.000880, std=0.000840, regu=0.002960 train accuracy is : 0.978000 val acc:  0.967900\n",
      " no decay lr=0.000880, std=0.000840,regu=0.002960 train accuracy is : 0.968000 val acc:  0.965200\n",
      "lr=0.000393, std=0.009509, regu=0.000164 train accuracy is : 0.985000 val acc:  0.962100\n",
      " no decay lr=0.000393, std=0.009509,regu=0.000164 train accuracy is : 0.981000 val acc:  0.971800\n",
      "lr=0.000896, std=0.008768, regu=0.000198 train accuracy is : 0.978000 val acc:  0.968500\n",
      " no decay lr=0.000896, std=0.008768,regu=0.000198 train accuracy is : 0.958000 val acc:  0.962800\n",
      "lr=0.000177, std=0.000226, regu=0.000303 train accuracy is : 0.965000 val acc:  0.962200\n",
      " no decay lr=0.000177, std=0.000226,regu=0.000303 train accuracy is : 0.977000 val acc:  0.970900\n",
      "lr=0.000150, std=0.000354, regu=0.010648 train accuracy is : 0.968000 val acc:  0.960400\n",
      " no decay lr=0.000150, std=0.000354,regu=0.010648 train accuracy is : 0.980000 val acc:  0.968900\n",
      "lr=0.000554, std=0.001164, regu=0.000926 train accuracy is : 0.990000 val acc:  0.966800\n",
      " no decay lr=0.000554, std=0.001164,regu=0.000926 train accuracy is : 0.973000 val acc:  0.968100\n",
      "lr=0.000641, std=0.000183, regu=0.039961 train accuracy is : 0.966000 val acc:  0.964700\n",
      " no decay lr=0.000641, std=0.000183,regu=0.039961 train accuracy is : 0.966000 val acc:  0.961300\n",
      "lr=0.000615, std=0.001292, regu=0.057556 train accuracy is : 0.975000 val acc:  0.961200\n",
      " no decay lr=0.000615, std=0.001292,regu=0.057556 train accuracy is : 0.967000 val acc:  0.959100\n",
      "lr=0.000559, std=0.008595, regu=0.004496 train accuracy is : 0.975000 val acc:  0.966400\n",
      " no decay lr=0.000559, std=0.008595,regu=0.004496 train accuracy is : 0.984000 val acc:  0.970800\n",
      "lr=0.000101, std=0.000116, regu=0.069380 train accuracy is : 0.959000 val acc:  0.952000\n",
      " no decay lr=0.000101, std=0.000116,regu=0.069380 train accuracy is : 0.963000 val acc:  0.959300\n",
      "lr=0.000134, std=0.007768, regu=0.000155 train accuracy is : 0.954000 val acc:  0.953400\n",
      " no decay lr=0.000134, std=0.007768,regu=0.000155 train accuracy is : 0.973000 val acc:  0.961800\n",
      "lr=0.000315, std=0.001194, regu=0.000290 train accuracy is : 0.979000 val acc:  0.965800\n",
      " no decay lr=0.000315, std=0.001194,regu=0.000290 train accuracy is : 0.985000 val acc:  0.970000\n",
      "lr=0.000191, std=0.002169, regu=0.001465 train accuracy is : 0.975000 val acc:  0.963000\n",
      " no decay lr=0.000191, std=0.002169,regu=0.001465 train accuracy is : 0.988000 val acc:  0.968900\n",
      "lr=0.000172, std=0.000131, regu=0.000205 train accuracy is : 0.974000 val acc:  0.962500\n",
      " no decay lr=0.000172, std=0.000131,regu=0.000205 train accuracy is : 0.979000 val acc:  0.970500\n",
      "lr=0.000224, std=0.001880, regu=0.004209 train accuracy is : 0.971000 val acc:  0.962900\n",
      " no decay lr=0.000224, std=0.001880,regu=0.004209 train accuracy is : 0.990000 val acc:  0.968000\n",
      "lr=0.000262, std=0.001563, regu=0.000296 train accuracy is : 0.979000 val acc:  0.964500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-f992cc09b794>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     43\u001b[0m                 }\n\u001b[0;32m     44\u001b[0m          )\n\u001b[1;32m---> 45\u001b[1;33m     \u001b[0msolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m' no decay lr=%f, std=%f,regu=%f train accuracy is : %f val acc:  %f'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_scale\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mregu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_acc_history\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mval_acc_history\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/burc/assignment2/cs231n/solver.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m       \u001b[1;31m# Maybe print training loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/burc/assignment2/cs231n/solver.pyc\u001b[0m in \u001b[0;36m_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;31m# Compute loss and gradient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/burc/assignment2/cs231n/classifiers/fc_net_split.pyc\u001b[0m in \u001b[0;36mloss\u001b[1;34m(self, X, y, noise, noise2, test, parallel_samples_output)\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[0mhidden_cache3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[0mhidden_cache4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m     \u001b[0mout1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtmp1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maffine_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W1_1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b1_1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m     \u001b[0mout2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtmp2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maffine_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W1_2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b1_2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[0mout3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtmp3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maffine_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W1_3'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b1_3'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/burc/assignment2/cs231n/layers.pyc\u001b[0m in \u001b[0;36maffine_forward\u001b[1;34m(x, w, b)\u001b[0m\n\u001b[0;32m     29\u001b[0m   \u001b[1;31m#############################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m   \u001b[0mx_reshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m   \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_reshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m   \u001b[1;31m#############################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m   \u001b[1;31m#                             END OF YOUR CODE                              #\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    #learning_rate = 0.000830 #10**np.random.uniform(-4,-3)\n",
    "    #weight_scale = 0.003849 #10**np.random.uniform(-3,-1)\n",
    "    #regu = 0.00168276907439#10**np.random.uniform(-3,-1)\n",
    "    regu=10**np.random.uniform(-4,-1)\n",
    "    learning_rate = 10**np.random.uniform(-4,-3)\n",
    "    weight_scale = 10**np.random.uniform(-4,-2)\n",
    "    #regu =0.00329329787291\n",
    "    #print regu\n",
    "    #learning_rate=0.0005\n",
    "    #weight_scale=0.027\n",
    "    #learning_rate = 0.001 #10**np.random.uniform(-5,-1)\n",
    "    #weight_scale = 0.02 #10**np.random.uniform(-3,0)\n",
    "    # no decay lr=0.000292, std=0.004709, train accuracy is : 0.999000 val acc:  0.970500\n",
    "#0.14912609128\n",
    "#0.00669438412009\n",
    "#0.00168276907439\n",
    "# no decay lr=0.000830, std=0.003849, train accuracy is : 0.994000 val acc:  0.967100\n",
    "# no decay lr=0.000508, std=0.027556, train accuracy is : 1.000000 val acc:  0.971500\n",
    "\n",
    "    model = TwoLayerNet(hidden_dim=256,input_dim=28*28,\n",
    "              weight_scale=weight_scale, reg=regu, activation=3, scores_activation=3)\n",
    "    solver = Solver(model,data,\n",
    "                print_every=10, num_epochs=60, batch_size=100,\n",
    "                update_rule='sgd_momentum',lr_decay=0.95,verbose = False,\n",
    "                optim_config={\n",
    "                  'learning_rate': learning_rate\n",
    "                }\n",
    "         )\n",
    "    \n",
    "    solver.train()\n",
    "\n",
    "    print 'lr=%f, std=%f, regu=%f train accuracy is : %f val acc:  %f' %(learning_rate, weight_scale, regu, solver.train_acc_history[-1], solver.val_acc_history[-1])\n",
    " \n",
    "\n",
    "    model = TwoLayerNet(hidden_dim=256,input_dim=28*28,\n",
    "              weight_scale=weight_scale, reg=regu,activation=3, scores_activation=3)\n",
    "    solver = Solver(model,data,\n",
    "                print_every=4000, num_epochs=60, batch_size=100,\n",
    "                update_rule='sgd_momentum',lr_decay=1.0,verbose =False, #lr_decay=0.0,\n",
    "                optim_config={\n",
    "                  'learning_rate': learning_rate\n",
    "                }\n",
    "         )\n",
    "    solver.train()\n",
    "    print ' no decay lr=%f, std=%f,regu=%f train accuracy is : %f val acc:  %f' %(learning_rate, weight_scale,regu, solver.train_acc_history[-1], solver.val_acc_history[-1])\n",
    " \n",
    "\n",
    "\n",
    "#solver.train()\n",
    "\n",
    "plt.plot(solver.loss_history, 'o')\n",
    "plt.title('Training loss history')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Training loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7840,)\n",
      "0 1231\n",
      "(10, 28, 28)\n",
      "0 1 784 28\n",
      "(10, 784)\n"
     ]
    }
   ],
   "source": [
    "y= np.array(range(0,28*28*10))\n",
    "print y.shape\n",
    "\n",
    "print y[0], y[1231]\n",
    "y2= np.reshape(y,(10,28,28))\n",
    "print y2.shape\n",
    "print y2[0,0,0], y2[0,0,1], y2[1,0,0], y2[0,1,0]\n",
    "\n",
    "y3 = np.reshape(y2, (y2.shape[0],-1))\n",
    "print y3.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " no decay lr=0.000356, std=0.000535,regu=0.004881 train accuracy is : 0.988000 val acc:  0.970400\n"
     ]
    }
   ],
   "source": [
    "##no decay lr=0.000986, std=0.004749,regu=0.000312 train accuracy is : 0.989000 val acc:  0.979100\n",
    "## no decay lr=0.000356, std=0.000535,regu=0.004881 train accuracy is : 0.981000 val acc:  0.972500\n",
    "regu=0.004881\n",
    "learning_rate =0.000356\n",
    "weight_scale = 0.000535\n",
    "\n",
    "\n",
    "model = TwoLayerNet(hidden_dim=256,input_dim=28*28,\n",
    "weight_scale=weight_scale, reg=regu,activation=3, scores_activation=3)\n",
    "solver = Solver(model,data,\n",
    "                print_every=4000, num_epochs=60, batch_size=100,\n",
    "                update_rule='sgd_momentum',lr_decay=1.0,verbose =False, #lr_decay=0.0,\n",
    "                optim_config={\n",
    "                  'learning_rate': learning_rate\n",
    "                }\n",
    "         )\n",
    "solver.train()\n",
    "print ' no decay lr=%f, std=%f,regu=%f train accuracy is : %f val acc:  %f' %(learning_rate, weight_scale,regu, solver.train_acc_history[-1], solver.val_acc_history[-1])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('W1_1ext784-256-10-3level', model.params['W1_1'])\n",
    "np.save('b1_1ext784-256-10-3level', model.params['b1_1'])\n",
    "np.save('W1_2ext784-256-10-3level', model.params['W1_2'])\n",
    "np.save('b1_2ext784-256-10-3level', model.params['b1_2'])\n",
    "np.save('W1_3ext784-256-10-3level', model.params['W1_3'])\n",
    "np.save('b1_3ext784-256-10-3level', model.params['b1_3'])\n",
    "np.save('W1_4ext784-256-10-3level', model.params['W1_4'])\n",
    "np.save('b1_4ext784-256-10-3level', model.params['b1_4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set accuracy:  0.9723\n",
      "Test set accuracy:  0.9699\n",
      "Noisy test set accuracy:  0.9695\n",
      "0.961085\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-f802c9a5d2ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0maa\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m   \u001b[0my_test_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'X_test'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnoise\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnoise2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparallel_samples_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m   \u001b[1;31m#print 'Noisy test set accuracy: ', (y_test_pred == data['y_test']).mean()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m   \u001b[0maa\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maa\u001b[0m\u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_test_pred\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y_test'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/burc/assignment2/cs231n/classifiers/fc_net_split.py\u001b[0m in \u001b[0;36mloss\u001b[1;34m(self, X, y, noise, noise2, test, parallel_samples_output)\u001b[0m\n\u001b[0;32m    150\u001b[0m       \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m       \u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m250\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m       \u001b[0mrandsel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m       \u001b[0mrandint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandsel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/burc/anaconda2/lib/python2.7/site-packages/numpy/core/fromnumeric.pyc\u001b[0m in \u001b[0;36mround_\u001b[1;34m(a, decimals, out)\u001b[0m\n\u001b[0;32m   2791\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2792\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'round'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2793\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecimals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "y_test_pred = np.argmax(model.loss(data['X_test'],noise=0,test=1), axis=1)\n",
    "y_val_pred = np.argmax(model.loss(data['X_val']), axis=1)\n",
    "print 'Validation set accuracy: ', (y_val_pred == data['y_val']).mean()\n",
    "print 'Test set accuracy: ', (y_test_pred == data['y_test']).mean()\n",
    "y_test_pred = np.argmax(model.loss(data['X_test'],noise=1,test=1), axis=1)\n",
    "print 'Noisy test set accuracy: ', (y_test_pred == data['y_test']).mean()\n",
    "\n",
    "#y_test_pred = np.argmax(model.loss(data['X_test'],noise=1,test=1,noise2=1, parallel_samples_output=32), axis=1)\n",
    "#print 'Noisy test set accuracy: ', (y_test_pred == data['y_test']).mean()\n",
    "\n",
    "\n",
    "par=1\n",
    "aa=0.0\n",
    "for i in range(0,20):\n",
    "  y_test_pred = np.argmax(model.loss(data['X_test'],noise=1,test=1,noise2=1, parallel_samples_output=par), axis=1)\n",
    "  #print 'Noisy test set accuracy: ', (y_test_pred == data['y_test']).mean()\n",
    "  aa=aa+ (y_test_pred == data['y_test']).mean()\n",
    "print aa/20\n",
    "\n",
    "par=2\n",
    "aa=0.0\n",
    "for i in range(0,20):\n",
    "  y_test_pred = np.argmax(model.loss(data['X_test'],noise=1,test=1,noise2=1, parallel_samples_output=par), axis=1)\n",
    "  #print 'Noisy test set accuracy: ', (y_test_pred == data['y_test']).mean()\n",
    "  aa=aa+ (y_test_pred == data['y_test']).mean()\n",
    "print aa/20\n",
    "\n",
    "\n",
    "par=3\n",
    "aa=0.0\n",
    "for i in range(0,20):\n",
    "  y_test_pred = np.argmax(model.loss(data['X_test'],noise=1,test=1,noise2=1, parallel_samples_output=par), axis=1)\n",
    "  #print 'Noisy test set accuracy: ', (y_test_pred == data['y_test']).mean()\n",
    "  aa=aa+ (y_test_pred == data['y_test']).mean()\n",
    "print aa/20\n",
    "\n",
    "par=4\n",
    "aa=0.0\n",
    "for i in range(0,20):\n",
    "  y_test_pred = np.argmax(model.loss(data['X_test'],noise=1,test=1,noise2=1, parallel_samples_output=par), axis=1)\n",
    "  #print 'Noisy test set accuracy: ', (y_test_pred == data['y_test']).mean()\n",
    "  aa=aa+ (y_test_pred == data['y_test']).mean()\n",
    "print aa/20\n",
    "\n",
    "par=8\n",
    "aa=0.0\n",
    "for i in range(0,20):\n",
    "  y_test_pred = np.argmax(model.loss(data['X_test'],noise=1,test=1,noise2=1, parallel_samples_output=par), axis=1)\n",
    "  #print 'Noisy test set accuracy: ', (y_test_pred == data['y_test']).mean()\n",
    "  aa=aa+ (y_test_pred == data['y_test']).mean()\n",
    "print aa/20\n",
    "\n",
    "par=16\n",
    "aa=0.0\n",
    "for i in range(0,20):\n",
    "  y_test_pred = np.argmax(model.loss(data['X_test'],noise=1,test=1,noise2=1, parallel_samples_output=par), axis=1)\n",
    "  #print 'Noisy test set accuracy: ', (y_test_pred == data['y_test']).mean()\n",
    "  aa=aa+ (y_test_pred == data['y_test']).mean()\n",
    "print aa/20\n",
    "\n",
    "par=24\n",
    "aa=0.0\n",
    "for i in range(0,20):\n",
    "  y_test_pred = np.argmax(model.loss(data['X_test'],noise=1,test=1,noise2=1, parallel_samples_output=par), axis=1)\n",
    "  #print 'Noisy test set accuracy: ', (y_test_pred == data['y_test']).mean()\n",
    "  aa=aa+ (y_test_pred == data['y_test']).mean()\n",
    "print aa/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Test set accuracy:  0.9699\n",
    "\n",
    "0.961125\n",
    "0.964415\n",
    "0.96585\n",
    "0.96679\n",
    "0.96733\n",
    "0.967365\n",
    "0.967565\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
