{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/burc/anaconda2/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "0.0\n",
      "255.0\n",
      "(50000, 28, 28)\n",
      "0.0\n",
      "255.0\n",
      "X_val:  (10000, 28, 28)\n",
      "X_train:  (50000, 28, 28)\n",
      "X_test:  (10000, 28, 28)\n",
      "y_val:  (10000,)\n",
      "y_train:  (50000,)\n",
      "y_test:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nn.classifiers.fc_net_split3 import *\n",
    "from nn.data_utils import get_CIFAR10_data\n",
    "from nn.data_utils_mnist import *\n",
    "from nn.gradient_check import eval_numerical_gradient, eval_numerical_gradient_array\n",
    "from nn.solver import Solver\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "data = get_MNIST_data(test_trinary=0,train_trinary=0,val_trinary=0,noise_amplitude=0.0,no_of_levels=5)\n",
    "for k, v in data.iteritems():\n",
    "  print '%s: ' % k, v.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=data['X_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr=0.008612, std=0.018905, regu=0.002606 train accuracy is : 0.988000 val acc:  0.975900\n",
      " no decay lr=0.008612, std=0.018905,regu=0.002606 train accuracy is : 0.961000 val acc:  0.966500\n",
      "lr=0.001386, std=0.004082, regu=0.000592 train accuracy is : 0.913000 val acc:  0.900600\n",
      " no decay lr=0.001386, std=0.004082,regu=0.000592 train accuracy is : 0.985000 val acc:  0.975700\n",
      "lr=0.000498, std=0.005052, regu=0.000878 train accuracy is : 0.906000 val acc:  0.876500\n",
      " no decay lr=0.000498, std=0.005052,regu=0.000878 train accuracy is : 0.907000 val acc:  0.904500\n",
      "lr=0.000914, std=0.003480, regu=0.000228 train accuracy is : 0.992000 val acc:  0.973300\n",
      " no decay lr=0.000914, std=0.003480,regu=0.000228 train accuracy is : 0.984000 val acc:  0.975600\n",
      "lr=0.004620, std=0.017062, regu=0.000321 train accuracy is : 0.986000 val acc:  0.976400\n",
      " no decay lr=0.004620, std=0.017062,regu=0.000321 train accuracy is : 0.970000 val acc:  0.967600\n",
      "lr=0.001163, std=0.099916, regu=0.008308 train accuracy is : 0.961000 val acc:  0.947200\n",
      " no decay lr=0.001163, std=0.099916,regu=0.008308 train accuracy is : 0.971000 val acc:  0.964200\n",
      "lr=0.000457, std=0.043412, regu=0.037498 train accuracy is : 0.924000 val acc:  0.943200\n",
      " no decay lr=0.000457, std=0.043412,regu=0.037498 train accuracy is : 0.959000 val acc:  0.952100\n",
      "lr=0.001057, std=0.038755, regu=0.000126 train accuracy is : 0.979000 val acc:  0.964400\n",
      " no decay lr=0.001057, std=0.038755,regu=0.000126 train accuracy is : 0.990000 val acc:  0.974100\n",
      "lr=0.001204, std=0.048715, regu=0.022548 train accuracy is : 0.954000 val acc:  0.957300\n",
      " no decay lr=0.001204, std=0.048715,regu=0.022548 train accuracy is : 0.966000 val acc:  0.962700\n",
      "lr=0.000104, std=0.007831, regu=0.044560 train accuracy is : 0.841000 val acc:  0.837300\n",
      " no decay lr=0.000104, std=0.007831,regu=0.044560 train accuracy is : 0.877000 val acc:  0.862400\n",
      "lr=0.003244, std=0.056511, regu=0.010109 train accuracy is : 0.990000 val acc:  0.968000\n",
      " no decay lr=0.003244, std=0.056511,regu=0.010109 train accuracy is : 0.967000 val acc:  0.969100\n",
      "lr=0.007525, std=0.017007, regu=0.005154 train accuracy is : 0.989000 val acc:  0.976300\n",
      " no decay lr=0.007525, std=0.017007,regu=0.005154 train accuracy is : 0.975000 val acc:  0.968200\n",
      "lr=0.005087, std=0.035055, regu=0.016589 train accuracy is : 0.978000 val acc:  0.968500\n",
      " no decay lr=0.005087, std=0.035055,regu=0.016589 train accuracy is : 0.972000 val acc:  0.967100\n",
      "lr=0.001928, std=0.006679, regu=0.037103 train accuracy is : 0.976000 val acc:  0.961100\n",
      " no decay lr=0.001928, std=0.006679,regu=0.037103 train accuracy is : 0.965000 val acc:  0.959400\n",
      "lr=0.007127, std=0.004160, regu=0.048986 train accuracy is : 0.968000 val acc:  0.954700\n",
      " no decay lr=0.007127, std=0.004160,regu=0.048986 train accuracy is : 0.926000 val acc:  0.933900\n",
      "lr=0.000406, std=0.033218, regu=0.002328 train accuracy is : 0.949000 val acc:  0.944300\n",
      " no decay lr=0.000406, std=0.033218,regu=0.002328 train accuracy is : 0.984000 val acc:  0.966000\n",
      "lr=0.003865, std=0.054529, regu=0.001253 train accuracy is : 0.989000 val acc:  0.974300\n",
      " no decay lr=0.003865, std=0.054529,regu=0.001253 train accuracy is : 0.980000 val acc:  0.974200\n",
      "lr=0.001972, std=0.010314, regu=0.078751 train accuracy is : 0.963000 val acc:  0.948700\n",
      " no decay lr=0.001972, std=0.010314,regu=0.078751 train accuracy is : 0.938000 val acc:  0.935100\n",
      "lr=0.000639, std=0.032802, regu=0.000110 train accuracy is : 0.973000 val acc:  0.959100\n",
      " no decay lr=0.000639, std=0.032802,regu=0.000110 train accuracy is : 0.989000 val acc:  0.973000\n",
      "lr=0.003173, std=0.058837, regu=0.024734 train accuracy is : 0.972000 val acc:  0.962300\n",
      " no decay lr=0.003173, std=0.058837,regu=0.024734 train accuracy is : 0.957000 val acc:  0.960700\n",
      "lr=0.000118, std=0.015299, regu=0.001923 train accuracy is : 0.928000 val acc:  0.922000\n",
      " no decay lr=0.000118, std=0.015299,regu=0.001923 train accuracy is : 0.966000 val acc:  0.956900\n",
      "lr=0.000128, std=0.007121, regu=0.000588 train accuracy is : 0.847000 val acc:  0.863100\n",
      " no decay lr=0.000128, std=0.007121,regu=0.000588 train accuracy is : 0.885000 val acc:  0.884700\n",
      "lr=0.000272, std=0.052739, regu=0.000147 train accuracy is : 0.933000 val acc:  0.928200\n",
      " no decay lr=0.000272, std=0.052739,regu=0.000147 train accuracy is : 0.966000 val acc:  0.951300\n",
      "lr=0.000136, std=0.005693, regu=0.005132 train accuracy is : 0.851000 val acc:  0.851500\n",
      " no decay lr=0.000136, std=0.005693,regu=0.005132 train accuracy is : 0.887000 val acc:  0.872500\n",
      "lr=0.000128, std=0.007906, regu=0.000153 train accuracy is : 0.846000 val acc:  0.860100\n",
      " no decay lr=0.000128, std=0.007906,regu=0.000153 train accuracy is : 0.897000 val acc:  0.882600\n",
      "lr=0.004537, std=0.079505, regu=0.012581 train accuracy is : 0.982000 val acc:  0.966000\n",
      " no decay lr=0.004537, std=0.079505,regu=0.012581 train accuracy is : 0.975000 val acc:  0.964500\n",
      "lr=0.001264, std=0.005086, regu=0.005892 train accuracy is : 0.906000 val acc:  0.899100\n",
      " no decay lr=0.001264, std=0.005086,regu=0.005892 train accuracy is : 0.984000 val acc:  0.976600\n",
      "lr=0.000539, std=0.041297, regu=0.000669 train accuracy is : 0.964000 val acc:  0.950400\n",
      " no decay lr=0.000539, std=0.041297,regu=0.000669 train accuracy is : 0.980000 val acc:  0.968800\n",
      "lr=0.000517, std=0.081379, regu=0.003173 train accuracy is : 0.940000 val acc:  0.932600\n",
      " no decay lr=0.000517, std=0.081379,regu=0.003173 train accuracy is : 0.964000 val acc:  0.952500\n",
      "lr=0.004640, std=0.051407, regu=0.000998 train accuracy is : 0.993000 val acc:  0.975200\n",
      " no decay lr=0.004640, std=0.051407,regu=0.000998 train accuracy is : 0.982000 val acc:  0.973400\n",
      "lr=0.003123, std=0.010676, regu=0.000224 train accuracy is : 0.996000 val acc:  0.978500\n",
      " no decay lr=0.003123, std=0.010676,regu=0.000224 train accuracy is : 0.978000 val acc:  0.971500\n",
      "lr=0.000364, std=0.061049, regu=0.000681 train accuracy is : 0.949000 val acc:  0.934700\n",
      " no decay lr=0.000364, std=0.061049,regu=0.000681 train accuracy is : 0.977000 val acc:  0.953900\n",
      "lr=0.000864, std=0.089518, regu=0.000288 train accuracy is : 0.944000 val acc:  0.937900\n",
      " no decay lr=0.000864, std=0.089518,regu=0.000288 train accuracy is : 0.975000 val acc:  0.959700\n",
      "lr=0.000568, std=0.060430, regu=0.057694 train accuracy is : 0.939000 val acc:  0.939300\n",
      " no decay lr=0.000568, std=0.060430,regu=0.057694 train accuracy is : 0.924000 val acc:  0.939800\n",
      "lr=0.003135, std=0.069857, regu=0.012289 train accuracy is : 0.985000 val acc:  0.964100\n",
      " no decay lr=0.003135, std=0.069857,regu=0.012289 train accuracy is : 0.971000 val acc:  0.966900\n",
      "lr=0.000886, std=0.035699, regu=0.000256 train accuracy is : 0.978000 val acc:  0.962200\n",
      " no decay lr=0.000886, std=0.035699,regu=0.000256 train accuracy is : 0.992000 val acc:  0.976100\n",
      "lr=0.000208, std=0.008931, regu=0.023189 train accuracy is : 0.835000 val acc:  0.870400\n",
      " no decay lr=0.000208, std=0.008931,regu=0.023189 train accuracy is : 0.967000 val acc:  0.962300\n",
      "lr=0.004484, std=0.027955, regu=0.002420 train accuracy is : 0.996000 val acc:  0.976100\n",
      " no decay lr=0.004484, std=0.027955,regu=0.002420 train accuracy is : 0.978000 val acc:  0.971800\n",
      "lr=0.006202, std=0.013781, regu=0.000352 train accuracy is : 0.983000 val acc:  0.973800\n",
      " no decay lr=0.006202, std=0.013781,regu=0.000352 train accuracy is : 0.967000 val acc:  0.966900\n",
      "lr=0.000711, std=0.014793, regu=0.000588 train accuracy is : 0.985000 val acc:  0.968500\n",
      " no decay lr=0.000711, std=0.014793,regu=0.000588 train accuracy is : 0.993000 val acc:  0.977300\n",
      "lr=0.000160, std=0.051113, regu=0.001555 train accuracy is : 0.928000 val acc:  0.915700\n",
      " no decay lr=0.000160, std=0.051113,regu=0.001555 train accuracy is : 0.966000 val acc:  0.938300\n",
      "lr=0.000734, std=0.011294, regu=0.000927 train accuracy is : 0.987000 val acc:  0.969800\n",
      " no decay lr=0.000734, std=0.011294,regu=0.000927 train accuracy is : 0.995000 val acc:  0.979100\n",
      "lr=0.000569, std=0.038550, regu=0.001500 train accuracy is : 0.970000 val acc:  0.951300\n",
      " no decay lr=0.000569, std=0.038550,regu=0.001500 train accuracy is : 0.982000 val acc:  0.967800\n",
      "lr=0.000406, std=0.005222, regu=0.034104 train accuracy is : 0.865000 val acc:  0.865400\n",
      " no decay lr=0.000406, std=0.005222,regu=0.034104 train accuracy is : 0.968000 val acc:  0.960800\n",
      "lr=0.000723, std=0.009831, regu=0.012000 train accuracy is : 0.979000 val acc:  0.969700\n",
      " no decay lr=0.000723, std=0.009831,regu=0.012000 train accuracy is : 0.989000 val acc:  0.974600\n",
      "lr=0.000505, std=0.027292, regu=0.070021 train accuracy is : 0.945000 val acc:  0.939300\n",
      " no decay lr=0.000505, std=0.027292,regu=0.070021 train accuracy is : 0.937000 val acc:  0.943100\n",
      "lr=0.004256, std=0.021617, regu=0.000172 train accuracy is : 0.992000 val acc:  0.977900\n",
      " no decay lr=0.004256, std=0.021617,regu=0.000172 train accuracy is : 0.962000 val acc:  0.966300\n",
      "lr=0.000575, std=0.011418, regu=0.000318 train accuracy is : 0.972000 val acc:  0.966700\n",
      " no decay lr=0.000575, std=0.011418,regu=0.000318 train accuracy is : 0.995000 val acc:  0.978400\n",
      "lr=0.000511, std=0.035658, regu=0.015772 train accuracy is : 0.966000 val acc:  0.949500\n",
      " no decay lr=0.000511, std=0.035658,regu=0.015772 train accuracy is : 0.973000 val acc:  0.962800\n",
      "lr=0.000604, std=0.015760, regu=0.001336 train accuracy is : 0.978000 val acc:  0.962700\n",
      " no decay lr=0.000604, std=0.015760,regu=0.001336 train accuracy is : 0.992000 val acc:  0.975000\n",
      "lr=0.004217, std=0.068099, regu=0.031679 train accuracy is : 0.964000 val acc:  0.957100\n",
      " no decay lr=0.004217, std=0.068099,regu=0.031679 train accuracy is : 0.944000 val acc:  0.949200\n",
      "lr=0.003414, std=0.004412, regu=0.010702 train accuracy is : 0.983000 val acc:  0.971500\n",
      " no decay lr=0.003414, std=0.004412,regu=0.010702 train accuracy is : 0.974000 val acc:  0.971300\n",
      "lr=0.000373, std=0.018597, regu=0.003301 train accuracy is : 0.965000 val acc:  0.955700\n",
      " no decay lr=0.000373, std=0.018597,regu=0.003301 train accuracy is : 0.987000 val acc:  0.969500\n",
      "lr=0.000387, std=0.030557, regu=0.026137 train accuracy is : 0.955000 val acc:  0.941700\n",
      " no decay lr=0.000387, std=0.030557,regu=0.026137 train accuracy is : 0.966000 val acc:  0.957000\n",
      "lr=0.000440, std=0.007556, regu=0.001136 train accuracy is : 0.891000 val acc:  0.881500\n",
      " no decay lr=0.000440, std=0.007556,regu=0.001136 train accuracy is : 0.992000 val acc:  0.975700\n",
      "lr=0.000515, std=0.060825, regu=0.008364 train accuracy is : 0.956000 val acc:  0.940800\n",
      " no decay lr=0.000515, std=0.060825,regu=0.008364 train accuracy is : 0.969000 val acc:  0.963600\n",
      "lr=0.005646, std=0.013788, regu=0.000362 train accuracy is : 0.982000 val acc:  0.973400\n",
      " no decay lr=0.005646, std=0.013788,regu=0.000362 train accuracy is : 0.972000 val acc:  0.966400\n",
      "lr=0.008943, std=0.043473, regu=0.001025 train accuracy is : 0.980000 val acc:  0.973000\n",
      " no decay lr=0.008943, std=0.043473,regu=0.001025 train accuracy is : 0.968000 val acc:  0.968500\n",
      "lr=0.006235, std=0.037990, regu=0.050883 train accuracy is : 0.966000 val acc:  0.949200\n",
      " no decay lr=0.006235, std=0.037990,regu=0.050883 train accuracy is : 0.938000 val acc:  0.939700\n",
      "lr=0.000122, std=0.084103, regu=0.001730 train accuracy is : 0.893000 val acc:  0.880300\n",
      " no decay lr=0.000122, std=0.084103,regu=0.001730 train accuracy is : 0.924000 val acc:  0.920000\n",
      "lr=0.003314, std=0.013747, regu=0.000845 train accuracy is : 0.992000 val acc:  0.978900\n",
      " no decay lr=0.003314, std=0.013747,regu=0.000845 train accuracy is : 0.983000 val acc:  0.972000\n",
      "lr=0.009783, std=0.096076, regu=0.000382 train accuracy is : 0.989000 val acc:  0.971300\n",
      " no decay lr=0.009783, std=0.096076,regu=0.000382 train accuracy is : 0.978000 val acc:  0.970300\n",
      "lr=0.000400, std=0.044600, regu=0.000230 train accuracy is : 0.943000 val acc:  0.940000\n",
      " no decay lr=0.000400, std=0.044600,regu=0.000230 train accuracy is : 0.975000 val acc:  0.960300\n",
      "lr=0.002650, std=0.003348, regu=0.000515 train accuracy is : 0.987000 val acc:  0.973400\n",
      " no decay lr=0.002650, std=0.003348,regu=0.000515 train accuracy is : 0.981000 val acc:  0.971000\n",
      "lr=0.001303, std=0.067776, regu=0.000326 train accuracy is : 0.967000 val acc:  0.958600\n",
      " no decay lr=0.001303, std=0.067776,regu=0.000326 train accuracy is : 0.988000 val acc:  0.970900\n",
      "lr=0.000319, std=0.086827, regu=0.000166 train accuracy is : 0.946000 val acc:  0.913100\n",
      " no decay lr=0.000319, std=0.086827,regu=0.000166 train accuracy is : 0.971000 val acc:  0.938100\n",
      "lr=0.000490, std=0.008897, regu=0.007892 train accuracy is : 0.892000 val acc:  0.887600\n",
      " no decay lr=0.000490, std=0.008897,regu=0.007892 train accuracy is : 0.982000 val acc:  0.974500\n",
      "lr=0.000185, std=0.030077, regu=0.001186 train accuracy is : 0.929000 val acc:  0.928600\n",
      " no decay lr=0.000185, std=0.030077,regu=0.001186 train accuracy is : 0.968000 val acc:  0.953800\n",
      "lr=0.000846, std=0.008764, regu=0.001391 train accuracy is : 0.975000 val acc:  0.972500\n",
      " no decay lr=0.000846, std=0.008764,regu=0.001391 train accuracy is : 0.993000 val acc:  0.980400\n",
      "lr=0.000302, std=0.030004, regu=0.068295 train accuracy is : 0.934000 val acc:  0.933000\n",
      " no decay lr=0.000302, std=0.030004,regu=0.068295 train accuracy is : 0.939000 val acc:  0.943900\n",
      "lr=0.001453, std=0.074144, regu=0.003513 train accuracy is : 0.968000 val acc:  0.957500\n",
      " no decay lr=0.001453, std=0.074144,regu=0.003513 train accuracy is : 0.989000 val acc:  0.972900\n",
      "lr=0.003548, std=0.023591, regu=0.000264 train accuracy is : 0.990000 val acc:  0.978400\n",
      " no decay lr=0.003548, std=0.023591,regu=0.000264 train accuracy is : 0.971000 val acc:  0.969700\n",
      "lr=0.002336, std=0.010219, regu=0.017653 train accuracy is : 0.980000 val acc:  0.970300\n",
      " no decay lr=0.002336, std=0.010219,regu=0.017653 train accuracy is : 0.978000 val acc:  0.973700\n",
      "lr=0.001044, std=0.008961, regu=0.001725 train accuracy is : 0.989000 val acc:  0.973700\n",
      " no decay lr=0.001044, std=0.008961,regu=0.001725 train accuracy is : 0.995000 val acc:  0.980500\n",
      "lr=0.000196, std=0.079451, regu=0.002668 train accuracy is : 0.925000 val acc:  0.908700\n",
      " no decay lr=0.000196, std=0.079451,regu=0.002668 train accuracy is : 0.947000 val acc:  0.932400\n",
      "lr=0.000106, std=0.014923, regu=0.000190 train accuracy is : 0.906000 val acc:  0.917100\n",
      " no decay lr=0.000106, std=0.014923,regu=0.000190 train accuracy is : 0.951000 val acc:  0.951500\n",
      "lr=0.003670, std=0.004876, regu=0.004999 train accuracy is : 0.988000 val acc:  0.974800\n",
      " no decay lr=0.003670, std=0.004876,regu=0.004999 train accuracy is : 0.982000 val acc:  0.974800\n",
      "lr=0.000132, std=0.026778, regu=0.001449 train accuracy is : 0.915000 val acc:  0.922400\n",
      " no decay lr=0.000132, std=0.026778,regu=0.001449 train accuracy is : 0.971000 val acc:  0.949800\n",
      "lr=0.000160, std=0.061257, regu=0.000313 train accuracy is : 0.923000 val acc:  0.909200\n",
      " no decay lr=0.000160, std=0.061257,regu=0.000313 train accuracy is : 0.955000 val acc:  0.935700\n",
      "lr=0.000446, std=0.011060, regu=0.004437 train accuracy is : 0.970000 val acc:  0.961500\n",
      " no decay lr=0.000446, std=0.011060,regu=0.004437 train accuracy is : 0.989000 val acc:  0.975300\n",
      "lr=0.000277, std=0.003919, regu=0.064204 train accuracy is : 0.862000 val acc:  0.858000\n",
      " no decay lr=0.000277, std=0.003919,regu=0.064204 train accuracy is : 0.879000 val acc:  0.875200\n",
      "lr=0.001545, std=0.030446, regu=0.000160 train accuracy is : 0.982000 val acc:  0.972600\n",
      " no decay lr=0.001545, std=0.030446,regu=0.000160 train accuracy is : 0.987000 val acc:  0.978000\n",
      "lr=0.000329, std=0.057716, regu=0.000328 train accuracy is : 0.942000 val acc:  0.928700\n",
      " no decay lr=0.000329, std=0.057716,regu=0.000328 train accuracy is : 0.971000 val acc:  0.952300\n",
      "lr=0.000108, std=0.009612, regu=0.000902 train accuracy is : 0.880000 val acc:  0.874000\n",
      " no decay lr=0.000108, std=0.009612,regu=0.000902 train accuracy is : 0.888000 val acc:  0.877500\n",
      "lr=0.000829, std=0.027488, regu=0.022726 train accuracy is : 0.971000 val acc:  0.959100\n",
      " no decay lr=0.000829, std=0.027488,regu=0.022726 train accuracy is : 0.976000 val acc:  0.965400\n",
      "lr=0.000150, std=0.003258, regu=0.017645 train accuracy is : 0.757000 val acc:  0.745500\n",
      " no decay lr=0.000150, std=0.003258,regu=0.017645 train accuracy is : 0.869000 val acc:  0.870500\n",
      "lr=0.000228, std=0.029181, regu=0.000119 train accuracy is : 0.950000 val acc:  0.933300\n",
      " no decay lr=0.000228, std=0.029181,regu=0.000119 train accuracy is : 0.960000 val acc:  0.958800\n",
      "lr=0.000768, std=0.039014, regu=0.001824 train accuracy is : 0.978000 val acc:  0.957800\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-aa94b066e26a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     48\u001b[0m                 }\n\u001b[0;32m     49\u001b[0m          )\n\u001b[1;32m---> 50\u001b[1;33m     \u001b[0msolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m' no decay lr=%f, std=%f,regu=%f train accuracy is : %f val acc:  %f'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_scale\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mregu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_acc_history\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mval_acc_history\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/burc/assignment2/cs231n/solver.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m       \u001b[1;31m# Maybe print training loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/burc/assignment2/cs231n/solver.pyc\u001b[0m in \u001b[0;36m_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;31m# Compute loss and gradient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/burc/assignment2/cs231n/classifiers/fc_net_split3.pyc\u001b[0m in \u001b[0;36mloss\u001b[1;34m(self, X, y, noise, noise2, test, parallel_samples_output)\u001b[0m\n\u001b[0;32m    280\u001b[0m     \u001b[1;31m# self.params[k]. Don't forget to add L2 regularization!                   #\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[1;31m#                                                                          #\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 282\u001b[1;33m     \u001b[1;31m# NOTE: To ensure that your implementation matches ours and you pass the   #\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    283\u001b[0m     \u001b[1;31m# automated tests, make sure that your L2 regularization includes a factor #\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[1;31m# of 0.5 to simplify the expression for the gradient.                      #\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/burc/assignment2/cs231n/layer_utils.pyc\u001b[0m in \u001b[0;36maffine_tanh_backward\u001b[1;34m(dout, cache)\u001b[0m\n\u001b[0;32m     55\u001b[0m   \u001b[0mfc_cache\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigmoid_cache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[0mda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtanh_backward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigmoid_cache\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m   \u001b[0mdx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maffine_backward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfc_cache\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/burc/assignment2/cs231n/layers.pyc\u001b[0m in \u001b[0;36maffine_backward\u001b[1;34m(dout, cache)\u001b[0m\n\u001b[0;32m     58\u001b[0m   \u001b[1;31m#############################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m   \u001b[0mx_reshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m   \u001b[0mdx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[0mdx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m   \u001b[0mdw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_reshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#lr=0.001573, std=0.012677, regu=0.000000 train accuracy is : 0.990000 val acc:  0.976600\n",
    "# no decay lr=0.001573, std=0.012677,regu=0.000000 train accuracy is : 0.981000 val acc:  0.977100\n",
    "\n",
    "for i in range(100):\n",
    "    #learning_rate = 0.000830 #10**np.random.uniform(-4,-3)\n",
    "    #weight_scale = 0.003849 #10**np.random.uniform(-3,-1)\n",
    "    #regu = 0.00168276907439#10**np.random.uniform(-3,-1)\n",
    "    regu=10**np.random.uniform(-4,-1)\n",
    "    #regu=0\n",
    "    learning_rate = 10**np.random.uniform(-4,-2)\n",
    "    weight_scale = 10**np.random.uniform(-2.5,-1)\n",
    "    \n",
    "    #regu =0.00329329787291\n",
    "    #print regu\n",
    "    #learning_rate=0.0005\n",
    "    #weight_scale=0.027\n",
    "    #learning_rate = 0.001 #10**np.random.uniform(-5,-1)\n",
    "    #weight_scale = 0.02 #10**np.random.uniform(-3,0)\n",
    "    # no decay lr=0.000292, std=0.004709, train accuracy is : 0.999000 val acc:  0.970500\n",
    "#0.14912609128\n",
    "#0.00669438412009\n",
    "#0.00168276907439\n",
    "# no decay lr=0.000830, std=0.003849, train accuracy is : 0.994000 val acc:  0.967100\n",
    "# no decay lr=0.000508, std=0.027556, train accuracy is : 1.000000 val acc:  0.971500\n",
    "\n",
    "    model = ThreeLayerNet(input_dim=28*28, ##hidden_dim=256,\n",
    "              weight_scale=weight_scale, reg=regu, activation=3, scores_activation=3)\n",
    "    solver = Solver(model,data,\n",
    "                print_every=10, num_epochs=60, batch_size=100,\n",
    "                update_rule='sgd_momentum',lr_decay=0.95,verbose = False,\n",
    "                optim_config={\n",
    "                  'learning_rate': learning_rate\n",
    "                }\n",
    "         )\n",
    "    \n",
    "    solver.train()\n",
    "\n",
    "    print 'lr=%f, std=%f, regu=%f train accuracy is : %f val acc:  %f' %(learning_rate, weight_scale, regu, solver.train_acc_history[-1], solver.val_acc_history[-1])\n",
    " \n",
    "\n",
    "    model = ThreeLayerNet(input_dim=28*28,  ##hidden_dim=256,\n",
    "              weight_scale=weight_scale, reg=regu,activation=3, scores_activation=3)\n",
    "    solver = Solver(model,data,\n",
    "                print_every=4000, num_epochs=60, batch_size=100, \n",
    "                update_rule='sgd_momentum',lr_decay=1.0,verbose =False, #lr_decay=0.0,\n",
    "                optim_config={\n",
    "                  'learning_rate': learning_rate\n",
    "                }\n",
    "         )\n",
    "    solver.train()\n",
    "    print ' no decay lr=%f, std=%f,regu=%f train accuracy is : %f val acc:  %f' %(learning_rate, weight_scale,regu, solver.train_acc_history[-1], solver.val_acc_history[-1])\n",
    " \n",
    "\n",
    "\n",
    "#solver.train()\n",
    "\n",
    "plt.plot(solver.loss_history, 'o')\n",
    "plt.title('Training loss history')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Training loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " no decay lr=0.001044, std=0.008961,regu=0.001725 train accuracy is : 0.996000 val acc:  0.981200\n"
     ]
    }
   ],
   "source": [
    "#no decay lr=0.001044, std=0.008961,regu=0.001725 train accuracy is : 0.995000 val acc:  0.980500\n",
    "\n",
    "regu=0.001725\n",
    "    #regu=0\n",
    "learning_rate = 0.001044\n",
    "weight_scale = 0.008961\n",
    "    \n",
    " \n",
    "model = ThreeLayerNet(input_dim=28*28,  ##hidden_dim=256,\n",
    "              weight_scale=weight_scale, reg=regu,activation=3, scores_activation=3)\n",
    "solver = Solver(model,data,\n",
    "                print_every=4000, num_epochs=60, batch_size=100, \n",
    "                update_rule='sgd_momentum',lr_decay=1.0,verbose =False, #lr_decay=0.0,\n",
    "                optim_config={\n",
    "                  'learning_rate': learning_rate\n",
    "                }\n",
    "         )\n",
    "solver.train()\n",
    "print ' no decay lr=%f, std=%f,regu=%f train accuracy is : %f val acc:  %f' %(learning_rate, weight_scale,regu, solver.train_acc_history[-1], solver.val_acc_history[-1])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set accuracy:  0.9812\n",
      "Test set accuracy:  0.9785\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = np.argmax(model.loss(data['X_test'],noise=0,test=1), axis=1)\n",
    "y_val_pred = np.argmax(model.loss(data['X_val']), axis=1)\n",
    "print 'Validation set accuracy: ', (y_val_pred == data['y_val']).mean()\n",
    "print 'Test set accuracy: ', (y_test_pred == data['y_test']).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7840,)\n",
      "0 1231\n",
      "(10, 28, 28)\n",
      "0 1 784 28\n",
      "(10, 784)\n"
     ]
    }
   ],
   "source": [
    "y= np.array(range(0,28*28*10))\n",
    "print y.shape\n",
    "\n",
    "print y[0], y[1231]\n",
    "y2= np.reshape(y,(10,28,28))\n",
    "print y2.shape\n",
    "print y2[0,0,0], y2[0,0,1], y2[1,0,0], y2[0,1,0]\n",
    "\n",
    "y3 = np.reshape(y2, (y2.shape[0],-1))\n",
    "print y3.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " no decay lr=0.000986, std=0.004749,regu=0.000312 train accuracy is : 0.984000 val acc:  0.976300\n"
     ]
    }
   ],
   "source": [
    "##no decay lr=0.000986, std=0.004749,regu=0.000312 train accuracy is : 0.989000 val acc:  0.979100\n",
    "regu=0.000312\n",
    "learning_rate = 0.000986\n",
    "weight_scale = 0.004749\n",
    "\n",
    "\n",
    "model = TwoLayerNet(hidden_dim=256,input_dim=28*28,\n",
    "weight_scale=weight_scale, reg=regu,activation=3, scores_activation=3)\n",
    "solver = Solver(model,data,\n",
    "                print_every=4000, num_epochs=60, batch_size=100,\n",
    "                update_rule='sgd_momentum',lr_decay=1.0,verbose =False, #lr_decay=0.0,\n",
    "                optim_config={\n",
    "                  'learning_rate': learning_rate\n",
    "                }\n",
    "         )\n",
    "solver.train()\n",
    "print ' no decay lr=%f, std=%f,regu=%f train accuracy is : %f val acc:  %f' %(learning_rate, weight_scale,regu, solver.train_acc_history[-1], solver.val_acc_history[-1])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set accuracy:  0.9772\n",
      "Test set accuracy:  0.9742\n",
      "Noisy test set accuracy:  0.9743\n",
      "Noisy test set accuracy:  0.9706\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = np.argmax(model.loss(data['X_test'],noise=0,test=1), axis=1)\n",
    "y_val_pred = np.argmax(model.loss(data['X_val']), axis=1)\n",
    "print 'Validation set accuracy: ', (y_val_pred == data['y_val']).mean()\n",
    "print 'Test set accuracy: ', (y_test_pred == data['y_test']).mean()\n",
    "y_test_pred = np.argmax(model.loss(data['X_test'],noise=1,test=1), axis=1)\n",
    "print 'Noisy test set accuracy: ', (y_test_pred == data['y_test']).mean()\n",
    "\n",
    "y_test_pred = np.argmax(model.loss(data['X_test'],noise=1,test=1,noise2=1, parallel_samples_output=32), axis=1)\n",
    "print 'Noisy test set accuracy: ', (y_test_pred == data['y_test']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
